\documentclass[11pt, a4paper]{article}
\usepackage{amsmath,amsfonts,amssymb, stackrel}
\usepackage{graphicx}
\usepackage[left=2cm, right=2cm, top=1.5cm, bottom=2.5cm]{geometry}
\usepackage{parskip}
\usepackage{relsize}
\usepackage[section]{placeins} 
\usepackage{listings}
\usepackage{graphics}
\usepackage[font=small,labelfont=bf]{caption}
\DeclareCaptionFont{scriptsize}{\scriptsize}

\author{Nicholas Peckham}
\title{Assessment 6: Modelling Yield Curves}
\date{\today}

\begin{document}

\maketitle

\section{Yields for November and December 1994} 

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{Yield.pdf}
\caption{Yield \% fitted against bond maturity shown in months}
\end{figure}
 

\subsection{Likelihood}

Considering a single month, the likelihood can be worked out as below:

We know the non-linear regression model is $y_{i,t} = \theta(\tau_{i}) + \epsilon_{i,t}$.

where: \[
\theta(\tau) = \beta_{1} + \beta_{2}(\dfrac{1-e^{-\lambda\tau}}{\lambda\tau}) + \beta_{3}(\dfrac{1-e^{-\lambda\tau}}{\lambda\tau} - e^{-\lambda\tau})
\]

The only known distribution is: $\epsilon_{i,t} \sim N(0, \sigma^{2})$

Therefore, we can write the regression in terms of $\epsilon$:
\[
\epsilon_{i,t} = y_{i,t} - \theta(\tau_{i})
\]

This means that the likelihood will take the form of: 
\[
L(\beta_{1}, \beta_{2}, \beta_{3}, \lambda, \sigma^{2} ) = \stackrel[i=1]{n}{\Pi}\dfrac{1}{\sqrt{\pi\sigma^{2}}}e^{-\dfrac{(y_{i,t}-\theta(\tau_{i}))^{2}}{2\sigma^{2}}}
\]

This in turn gives us:
\[
= (2\pi)^{-(\dfrac{n}{2})} (\sigma^{2})^{-(\dfrac{n}{2})} exp(\dfrac{-\stackrel[i=1]{n}{\Sigma}(y_{i,t} - \theta(\tau_{i}))^{2}}{2\sigma^{2}})
\]


Taking the log, to find the log-likelihood gives us:
\[
l(\beta_{1}, \beta_{2}, \beta_{3}, \lambda, \sigma^{2}) = -(\dfrac{n}{2})\log(2\pi) - (n)\log(\sigma) - \dfrac{1}{2\sigma^{2}}\stackrel[i=1]{n}{\Sigma}(y_{i,t} - \theta(\tau_{i}))^{2}
\]
 
\section{Question 3}

Find the least squares estimates for $\beta_{1}$, $\beta_{2}$ and $\beta_{3}$. Using the suggestion that $\lambda = 0.069$, and looking at only December 1994, we can treat the problem a linear regression.

First, the $\theta(\tau_{i})$ is entered into R:
\begin{verbatim}
lambda = 0.069
x1 = numeric(18)
x2 = numeric(18)
for (i in 1:18){
x1[i] = (1 - (exp(-lambda*tau[i])))/(lambda*tau[i])
x2[i] = x1[i] - exp(-lambda*tau[i])
}
\end{verbatim}

A linear regression model is then fit; the yield \% against $x1$ and $x2$:
\begin{verbatim}
> fit = lm(dec94 ~ x1 + x2)
> summary(fit)

Call:
lm(formula = dec94 ~ x1 + x2)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.38243 -0.13046 -0.02153  0.16018  0.25274 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   7.2381     0.1550  46.697  < 2e-16 ***
x1           -2.2325     0.1625 -13.738 6.67e-10 ***
x2            4.9934     0.5679   8.792 2.64e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1837 on 15 degrees of freedom
Multiple R-squared:  0.954,	Adjusted R-squared:  0.9479 
F-statistic: 155.6 on 2 and 15 DF,  p-value: 9.336e-11
\end{verbatim}

As we can see, this linear model gives out values for the coefficients:
\begin{itemize}
\item $\beta_{1}$ = 7.2381
\item $\beta_{2}$ = -2.2325
\item $\beta_{3}$ = 4.9934
\end{itemize}

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{testing.pdf}
\caption{Yield \% fitted against bond maturity shown in months for December 1994, with red line showing the linear fit to the model based on the coefficients for the intercept and the $\beta$'s, which shows a reasonable fit}
\end{figure}

\clearpage

We can show that these values based on the least squares estimates are also the maximum likelihood estimators for $\beta_{1}$, $\beta_{2}$ and $\beta_{3}$ by using the 'nlm' function in R. The 'nlm' function outputs the maximum likelihood estimators.

\begin{verbatim}
> func = function(param, dec94, x1, x2){
+   beta1 = param[1]
+   beta2 = param[2]
+   beta3 = param[3]
+   fitted = beta1 + (beta2*x1) + (beta3*x2)
+   sum((dec94 - fitted)^2)
+ }
> init.param = c(0, 1, 1)             %setting initial parameters
> nlm(func, init.param, dec94, x1, x2)
$minimum
[1] 0.5063474

$estimate
[1]  7.238072 -2.232471  4.993439

$gradient
[1] -9.344310e-10 -6.529639e-10  2.402455e-09

$code
[1] 1

$iterations
[1] 7

\end{verbatim}

As we can see, the estimators from the 'nlm' function are identical to the estimators found using linear regression.

As we know that the error terms are normally distributed: $\epsilon_{i,t} \sim N(0, \sigma^{2})$, we can work out $\sigma^{2} = 0.02813$:
\begin{verbatim}
> b = numeric(3)
> for(i in 1:3){
+   b[i] = nlm(func, init.param, dec94, x1, x2)$estimate[i]
+   fitted = b[1] + b[2]*x1 + b[3]*x2
+ }
> sig = sum((dec94 - fitted)^2)/length(dec94)
> sig
[1] 0.02813041
\end{verbatim}



\section{Question 4}

Using the method outlined in the question, it is possible to test over multiple values of $\lambda$ to find the value that produces the maximum likelihood estimation. We can find the value of $\lambda$ that produces the smallest standard deviation, under normal error assumption, and we can find the maximum likelihood estimators for December 1994. This is because the method of maximum likelihood chooses as estimates the values of the parameters that are most consistent with the sample data. 

\begin{verbatim}

lambda = seq(from = 0.01, to = 1, by = 0.001)
x1 = matrix(0, nrow = 18, ncol = length(lambda))
x2 = matrix(0, nrow = 18, ncol = length(lambda))

for(j in 1:length(lambda)){
  for (i in 1:18){
   x1[i,j] = (1 - (exp(-lambda[j]*tau[i])))/(lambda[j]*tau[i])
   x2[i,j] = x1[i] - exp(-lambda[j]*tau[i])
  }
}  


mylm = lapply(1:length(lambda), function(x) lm(dec94 ~ x1[,x] + x2[,x]))

s = sapply(mylm, coef)
sd = sapply(mylm, sigma)

plot(sd ~ lambda, type = "l", ylab = "standard deviation", main = "Lambda against standard deviation")
abline(h = 0.03685693, col = "red")

\end{verbatim}

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{lambda.pdf}
\caption{Different values of $\lambda$ fitted against standard deviation to find the value that minimises the standard deviation and thus variance}
\end{figure}


Uses this method, we come out with $\lambda = 0.288$, which maximises the likelihood. Taking this value, we can work out the maximum likelihood estimate of $(\beta_{1}, \beta_{2}, \beta_{3}, \sigma^{2}, \lambda)$:

\begin{verbatim}
lambda = 0.288
x1 = numeric(18)
x2 = numeric(18)
for (i in 1:18){
  x1[i] = (1 - (exp(-lambda*tau[i])))/(lambda*tau[i])
  x2[i] = x1[i] - exp(-lambda*tau[i])
}
x1
x2
\end{verbatim}

\begin{verbatim}
> fit = lm(dec94 ~ x1 + x2)
> summary(fit)

Call:
lm(formula = dec94 ~ x1 + x2)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.075459 -0.033303 -0.002245  0.032888  0.079156 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  7.83792    0.02238 350.254  < 2e-16 ***
x1          -3.65607    0.06695 -54.612  < 2e-16 ***
x2           1.29823    0.17315   7.498  1.9e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.05236 on 15 degrees of freedom
Multiple R-squared:  0.9963,	Adjusted R-squared:  0.9958 
F-statistic:  2000 on 2 and 15 DF,  p-value: < 2.2e-16
\end{verbatim}

As we can see, this linear model using $\lambda = 0.288$ gives out values for the coefficients:
\begin{itemize}
\item $\beta_{1}$ = 7.83792
\item $\beta_{2}$ = -3.65607
\item $\beta_{3}$ = 1.29823
\item $\sigma^{2}$ = 0.002284469
\end{itemize}

\begin{verbatim}
> fit = lm(dec94 ~ x1 + x2)
> b = numeric(3)
> for(i in 1:3){
+   b[i] = nlm(func, init.param, dec94, x1, x2)$estimate[i]
+   fitted = b[1] + b[2]*x1 + b[3]*x2
+ }
> sig = sum((dec94 - fitted)^2)/length(dec94)
> sig
[1] 0.002284469
\end{verbatim}



\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{testr.pdf}
\caption{Yield \% fitted against bond maturity shown in months for December 1994, with red line showing the linear fit to the model based on our estimate of $\lambda = 0.288$, and the blue line showing the previous fit to the model under $\lambda = 0.069$. As shown, the red line shows a much better fit to the data.} 
\end{figure}
 
\clearpage

Similar to previously, we can check whether these values are maxima:
\begin{verbatim}
> nlm(func, init.param, dec94, x1, x2)
$minimum
[1] 0.04112044

$estimate
[1]  7.837923 -3.656067  1.298232

$gradient
[1] -7.865426e-11 -3.595025e-10 -8.172324e-11

$code
[1] 1

$iterations
[1] 7
\end{verbatim}
As evidenced above, the values are indeed maximum estimators.

\section{Question 5}

To find 95\% confidence intervals for $\lambda$. 


\end{document}

